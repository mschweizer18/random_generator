{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playwright==1.25.2\n",
      "  Downloading playwright-1.25.2-py3-none-macosx_10_13_x86_64.whl (30.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.6 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting greenlet==1.1.2\n",
      "  Downloading greenlet-1.1.2-cp39-cp39-macosx_10_14_x86_64.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting websockets==10.1\n",
      "  Downloading websockets-10.1-cp39-cp39-macosx_10_9_x86_64.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyee==8.1.0\n",
      "  Downloading pyee-8.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Installing collected packages: websockets, pyee, greenlet, playwright\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 1.1.1\n",
      "    Uninstalling greenlet-1.1.1:\n",
      "      Successfully uninstalled greenlet-1.1.1\n",
      "Successfully installed greenlet-1.1.2 playwright-1.25.2 pyee-8.1.0 websockets-10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install playwright==1.25.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.sync_api import sync_playwright\n",
    "from dataclasses import dataclass, asdict, field\n",
    "import pandas as pd\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-s SEARCH] [-t TOTAL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"80cffc79-8448-4b22-bc4a-a79acf8d117f\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/Users/mayaschweizer/Library/Jupyter/runtime/kernel-v2-8715CNVRfBzPgmig.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayaschweizer/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Business:\n",
    "    \"\"\"holds business data\"\"\"\n",
    "\n",
    "    name: str = None\n",
    "    address: str = None\n",
    "    website: str = None\n",
    "    phone_number: str = None\n",
    "    reviews_count: int = None\n",
    "    reviews_average: float = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BusinessList:\n",
    "    \"\"\"holds list of Business objects,\n",
    "    and save to both excel and csv\n",
    "    \"\"\"\n",
    "\n",
    "    business_list: list[Business] = field(default_factory=list)\n",
    "\n",
    "    def dataframe(self):\n",
    "        \"\"\"transform business_list to pandas dataframe\n",
    "\n",
    "        Returns: pandas dataframe\n",
    "        \"\"\"\n",
    "        return pd.json_normalize(\n",
    "            (asdict(business) for business in self.business_list), sep=\"_\"\n",
    "        )\n",
    "    \n",
    "    def main():\n",
    "        with sync_playwright() as p:\n",
    "            browser = p.chromium.launch(headless=False)\n",
    "            page = browser.new_page()\n",
    "\n",
    "            page.goto(\"https://www.google.com/maps\", timeout=60000)\n",
    "        # wait is added for dev phase. can remove it in production\n",
    "            page.wait_for_timeout(5000)\n",
    "\n",
    "            page.locator('//input[@id=\"searchboxinput\"]').fill(search_for)\n",
    "            page.wait_for_timeout(3000)\n",
    "\n",
    "            page.keyboard.press(\"Enter\")\n",
    "            page.wait_for_timeout(5000)\n",
    "\n",
    "        # scrolling\n",
    "            page.hover('//a[contains(@href, \"https://www.google.com/maps/place\")]')\n",
    "\n",
    "        # this variable is used to detect if the bot\n",
    "        # scraped the same number of listings in the previous iteration\n",
    "            previously_counted = 0\n",
    "            while True:\n",
    "                page.mouse.wheel(0, 10000)\n",
    "                page.wait_for_timeout(3000)\n",
    "\n",
    "                if (\n",
    "                page.locator(\n",
    "                    '//a[contains(@href, \"https://www.google.com/maps/place\")]'\n",
    "                ).count()\n",
    "                >= total\n",
    "            ):\n",
    "                    listings = page.locator(\n",
    "                    '//a[contains(@href, \"https://www.google.com/maps/place\")]'\n",
    "                ).all()[:total]\n",
    "                    listings = [listing.locator(\"xpath=..\") for listing in listings]\n",
    "                    print(f\"Total Scraped: {len(listings)}\")\n",
    "                    break\n",
    "                else:\n",
    "                # logic to break from loop to not run infinitely\n",
    "                # in case arrived at all available listings\n",
    "                    if (\n",
    "                    page.locator(\n",
    "                        '//a[contains(@href, \"https://www.google.com/maps/place\")]'\n",
    "                    ).count()\n",
    "                    == previously_counted\n",
    "                ):\n",
    "                        listings = page.locator(\n",
    "                        '//a[contains(@href, \"https://www.google.com/maps/place\")]'\n",
    "                    ).all()\n",
    "                        print(f\"Arrived at all available\\nTotal Scraped: {len(listings)}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        previously_counted = page.locator(\n",
    "                        '//a[contains(@href, \"https://www.google.com/maps/place\")]'\n",
    "                    ).count()\n",
    "                        print(\n",
    "                        f\"Currently Scraped: \",\n",
    "                        page.locator(\n",
    "                            '//a[contains(@href, \"https://www.google.com/maps/place\")]'\n",
    "                        ).count(),\n",
    "                    )\n",
    "\n",
    "        business_list = BusinessList()\n",
    "\n",
    "        # scraping\n",
    "        for listing in listings:\n",
    "            listing.click()\n",
    "            page.wait_for_timeout(5000)\n",
    "\n",
    "            name_xpath = '//div[contains(@class, \"fontHeadlineSmall\")]'\n",
    "            address_xpath = '//button[@data-item-id=\"address\"]//div[contains(@class, \"fontBodyMedium\")]'\n",
    "            website_xpath = '//a[@data-item-id=\"authority\"]//div[contains(@class, \"fontBodyMedium\")]'\n",
    "            phone_number_xpath = '//button[contains(@data-item-id, \"phone:tel:\")]//div[contains(@class, \"fontBodyMedium\")]'\n",
    "            reviews_span_xpath = '//span[@role=\"img\"]'\n",
    "\n",
    "            business = Business()\n",
    "\n",
    "            if listing.locator(name_xpath).count() > 0:\n",
    "                business.name = listing.locator(name_xpath).inner_text()\n",
    "            else:\n",
    "                business.name = \"\"\n",
    "            if page.locator(address_xpath).count() > 0:\n",
    "                business.address = page.locator(address_xpath).inner_text()\n",
    "            else:\n",
    "                business.address = \"\"\n",
    "            if page.locator(website_xpath).count() > 0:\n",
    "                business.website = page.locator(website_xpath).inner_text()\n",
    "            else:\n",
    "                business.website = \"\"\n",
    "            if page.locator(phone_number_xpath).count() > 0:\n",
    "                business.phone_number = page.locator(phone_number_xpath).inner_text()\n",
    "            else:\n",
    "                business.phone_number = \"\"\n",
    "            if listing.locator(reviews_span_xpath).count() > 0:\n",
    "                business.reviews_average = float(\n",
    "                    listing.locator(reviews_span_xpath)\n",
    "                    .get_attribute(\"aria-label\")\n",
    "                    .split()[0]\n",
    "                    .replace(\",\", \".\")\n",
    "                    .strip()\n",
    "                )\n",
    "                business.reviews_count = int(\n",
    "                    listing.locator(reviews_span_xpath)\n",
    "                    .get_attribute(\"aria-label\")\n",
    "                    .split()[2]\n",
    "                    .strip()\n",
    "                )\n",
    "            else:\n",
    "                business.reviews_average = \"\"\n",
    "                business.reviews_count = \"\"\n",
    "\n",
    "            business_list.business_list.append(business)\n",
    "\n",
    "        # saving to both excel and csv just to showcase the features.\n",
    "\n",
    "        browser.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-s\", \"--search\", type=str)\n",
    "    parser.add_argument(\"-t\", \"--total\", type=int)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.search:\n",
    "        search_for = args.search\n",
    "    else:\n",
    "        # in case no arguments passed\n",
    "        # the scraper will search by defaukt for:\n",
    "        search_for = \"london restaurants\"\n",
    "\n",
    "    # total number of products to scrape. Default is 10\n",
    "    if args.total:\n",
    "        total = args.total\n",
    "    else:\n",
    "        total = 1000\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
